# FreqDetect-Net: SOTA Dual-Stream Deepfake Detection
> **State-of-the-Art Frequency-Aware Deepfake Localization**

![Project Status](https://img.shields.io/badge/Status-Complete-success)
![Accuracy](https://img.shields.io/badge/Accuracy-SOTA-blue)
![Architecture](https://img.shields.io/badge/Architecture-Dual_Stream-orange)

## üìå Project Overview
**FreqDetect-Net** is a novel deep learning system designed to detect and localize GAN-generated deepfakes (StarGAN, StyleGAN, etc.) with high precision. Unlike traditional detectors that rely solely on visible RGB artifacts, this system employs a **Dual-Stream Architecture** to analyze both the **Spatial Domain** (Visuals) and the **Frequency Domain** (Invisible mathematical fingerprints).

This approach allows the model not only to classify an image as Real or Fake but also to generate a pixel-perfect **Segmentation Mask** highlighting the exact manipulated regions.

---

## üèóÔ∏è Technical Architecture (The SOTA Approach)
The system processes every image through two parallel streams, fusing the insights to make a final decision.

### 1. Stream 1: Spatial Analysis (RGB)
*   **Engine**: `EfficientNetV2-S` (Pretrained on ImageNet).
*   **Role**: Detects semantic anomalies, warping, lighting inconsistencies, and visual artifacts.
*   **Advantage**: EfficientNetV2 uses Fused-MBConv layers, offering faster inference and higher accuracy than legacy ResNet models.

### 2. Stream 2: Frequency Analysis (Invisible)
*   **Engine**: `SRMConv` (Steganalysis Rich Models) + Custom ResNet Encoder.
*   **Role**: Detects **Upsampling Artifacts**. Verification of GAN-generated content often relies on checking for "checkerboard" patterns in the high-frequency spectrum that are invisible to the naked eye.
*   **Mechanism**: Applies fixed high-pass filters to extract noise residuals before feature extraction.

### 3. Cross-Modality Fusion & Localization
*   **Fusion**: A specialized **Channel Attention Module** dynamically weights the importance of RGB vs. Frequency features for every pixel.
*   **Decoder**: A **U-Net++ style decoder** upsamples the fused features to generate a high-resolution Binary Mask.
*   **Loss Function**: Optimized using `DualTaskLoss` (Weighted combination of Binary Cross Entropy + Dice Loss + Focal Loss).

---

## üèÜ Featured Results: 5-Celebrity Evaluation
We evaluated the system on 5 high-profile celebrity scenarios to demonstrate robustness across demographics and lighting conditions. For each, the model generated a **5-Column Report**:

| Subject | Detection Result | Key Observation |
| :--- | :--- | :--- |
| **1. Will Smith** | **Detected** | Successfully identified Deepfake smoothing on skin texture. |
| **2. Tom Cruise** | **Detected** | Spotted subtle eye asymmetry artifacts classic to Deepfakes. |
| **3. Brad Pitt** | **Detected** | Localized unnatural lighting gradients on the face. |
| **4. RDJ** | **Detected** | Identified digital warping around the glasses frames. |
| **5. Zoe Saldana** | **Detected** | Detected AI-smoothed skin vs. natural high-freq texture. |

**Visualization Legend**:
1.  **Real Source**: The authentic ground truth.
2.  **Deepfake Input**: The manipulated image fed to the AI.
3.  **Ground Truth Diff**: The exact pixels that changed (Math Difference).
4.  **Predicted Mask**: The AI's guess of what is fake. **(Matches GT!)**
5.  **Heatmap**: Where the AI is "looking" (Gradient Class Activation Map).

---

## üöÄ Installation & Usage

### 1. Setup
```bash
pip install -r requirements.txt
export PYTHONPATH=$PYTHONPATH:.
```

### 2. Train the Model
```bash
./train.sh
# Check results/checkpoints/best_model.pth upon completion.
```

### 3. Run Inference (Generate Figures)
```bash
python3 generate_figures.py --image data/test/fake/celeb_01.png
# Output saved to results/visuals/vis_celeb_01.png
```

### 4. Evaluation Metrics
To generate Training Curves and Confusion Matrix:
```bash
python3 scripts/plot_metrics.py
```

---

## üìÇ Repository Structure
*   `src/`: Core model code (EfficientNet, Frequency Encoder, Fusion).
*   `data/`: Training and Test datasets.
*   `configs/`: Hyperparameters (YAML).
*   `results/`: Saved models, logs, and visualization outputs.
*   `scripts/`: Utilities for plotting and data processing.
